{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from cerebro.backend import SparkBackend\n",
    "from cerebro.keras import SparkEstimator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e38bb7a20e4a3d9959252b717060f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=7, continuous_update=False, description='Test:', max=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sli = widgets.IntSlider(\n",
    "    value=7,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Test:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "sli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943f5257cc25469593d34c7033e0a032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with out:\n",
    "    for i in range(3):\n",
    "        print(i, 'Hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e38bb7a20e4a3d9959252b717060f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10, continuous_update=False, description='Test:', max=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out.append_display_data(sli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sli.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Lee/opt/anaconda3/lib/python3.7/site-packages/cerebro_dl-1.0.0-py3.7.egg/cerebro/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import cerebro\n",
    "print(os.path.abspath(cerebro.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas storage for intermediate data and model artifacts.\n",
    "from cerebro.storage import LocalStore, HDFSStore\n",
    "\n",
    "# Model selection/AutoML methods.\n",
    "from cerebro.tune import GridSearch, RandomSearch, TPESearch\n",
    "\n",
    "# Utility functions for specifying the search space.\n",
    "from cerebro.tune import hp_choice, hp_uniform, hp_quniform, hp_loguniform, hp_qloguniform\n",
    "\n",
    "import tensorflow as tf\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "def wait_for_change(widget, value):\n",
    "    future = asyncio.Future()\n",
    "    def getvalue(change):\n",
    "        # make the new value available\n",
    "        future.set_result(change.new)\n",
    "        widget.unobserve(getvalue, value)\n",
    "    widget.observe(getvalue, value)\n",
    "    return future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fad4249d684b2dba22e82c40f6a08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did work 0\n",
      "async function continued with value 26\n",
      "did work 1\n",
      "async function continued with value 42\n",
      "did work 2\n",
      "async function continued with value 75\n",
      "did work 3\n",
      "async function continued with value 42\n",
      "did work 4\n",
      "async function continued with value 23\n",
      "did work 5\n",
      "async function continued with value 65\n",
      "did work 6\n",
      "async function continued with value 51\n",
      "did work 7\n",
      "async function continued with value 35\n",
      "did work 8\n",
      "async function continued with value 15\n",
      "did work 9\n",
      "async function continued with value 44\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import IntSlider\n",
    "slider = IntSlider()\n",
    "\n",
    "async def f():\n",
    "    for i in range(10):\n",
    "        print('did work %s'%i)\n",
    "        x = await wait_for_change(slider, 'value')\n",
    "        print('async function continued with value %s'%x)\n",
    "asyncio.ensure_future(f())\n",
    "\n",
    "slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-02-23 15:22:50, Running 1 Workers\n",
      "CEREBRO => Time: 2021-02-23 15:22:51, Preparing Data\n",
      "CEREBRO => Time: 2021-02-23 15:22:51, Num Partitions: 8\n",
      "CEREBRO => Time: 2021-02-23 15:22:51, Writing DataFrames\n",
      "CEREBRO => Time: 2021-02-23 15:22:51, Train Data Path: file:///Users/Lee/Documents/Research/MS_Thesis/Trial/intermediate_train_data\n",
      "CEREBRO => Time: 2021-02-23 15:22:51, Val Data Path: file:///Users/Lee/Documents/Research/MS_Thesis/Trial/intermediate_val_data\n",
      "CEREBRO => Time: 2021-02-23 15:22:54, Train Partitions: 6\n",
      "CEREBRO => Time: 2021-02-23 15:23:04, Val Partitions: 2\n",
      "CEREBRO => Time: 2021-02-23 15:23:11, Train Rows: 65\n",
      "CEREBRO => Time: 2021-02-23 15:23:11, Val Rows: 22\n",
      "CEREBRO => Time: 2021-02-23 15:23:11, Initializing Workers\n",
      "CEREBRO => Time: 2021-02-23 15:23:11, Initializing Data Loaders\n",
      "CEREBRO => Time: 2021-02-23 15:23:12, Launching Model Selection Workload\n",
      "CEREBRO => Time: 2021-02-23 15:23:12, Model: model_0_1614064992, batch_size: 96, lr: 0.001\n",
      "CEREBRO => Time: 2021-02-23 15:23:12, Starting EPOCH Training\n",
      "CEREBRO => Time: 2021-02-23 15:23:12, Scheduling Model: model_0_1614064992, on Worker: 0\n",
      "CEREBRO => Time: 2021-02-23 15:23:12, Scheduled Model: model_0_1614064992, on Worker: 0\n",
      "CEREBRO => Time: 2021-02-23 15:23:14, Completed Model: model_0_1614064992, on Worker: 0\n",
      "CEREBRO => Time: 2021-02-23 15:23:16, Starting EPOCH Validation\n",
      "CEREBRO => Time: 2021-02-23 15:23:16, Scheduling Model: model_0_1614064992, on Worker: 0\n",
      "CEREBRO => Time: 2021-02-23 15:23:16, Scheduled Model: model_0_1614064992, on Worker: 0\n",
      "CEREBRO => Time: 2021-02-23 15:23:18, Completed Model: model_0_1614064992, on Worker: 0\n",
      "CEREBRO => Time: 2021-02-23 15:23:20, Model: model_0_1614064992, Epoch: 1, train_loss: 63.19040298461914, train_acc: 0.3645833432674408, val_loss: 0.0011456037173047662, val_acc: 1.0\n",
      "CEREBRO => Time: 2021-02-23 15:23:20, Starting EPOCH Training\n",
      "CEREBRO => Time: 2021-02-23 15:23:20, Scheduling Model: model_0_1614064992, on Worker: 0\n",
      "CEREBRO => Time: 2021-02-23 15:23:20, Scheduled Model: model_0_1614064992, on Worker: 0\n",
      "CEREBRO => Time: 2021-02-23 15:23:21, Terminating Workers\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9d8469810729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Perform model selection. Returns best model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Inspect best model training history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/cerebro_dl-1.0.0-py3.7.egg/cerebro/tune/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    200\u001b[0m             if self.verbose >= 1: print('CEREBRO => Time: {}, Launching Model Selection Workload'.format(\n\u001b[1;32m    201\u001b[0m                 datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_on_prepared_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/cerebro_dl-1.0.0-py3.7.egg/cerebro/tune/tpe.py\u001b[0m in \u001b[0;36m_fit_on_prepared_data\u001b[0;34m(self, dataset_idx, metadata)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 epoch_results = self.backend.train_for_one_epoch(estimators, self.store, dataset_idx, self.feature_cols,\n\u001b[0;32m--> 135\u001b[0;31m                                                                  self.label_cols)\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0mupdate_model_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/cerebro_dl-1.0.0-py3.7.egg/cerebro/backend/spark/backend.py\u001b[0m in \u001b[0;36mtrain_for_one_epoch\u001b[0;34m(self, models, store, dataset_idx, feature_col, label_col, is_train)\u001b[0m\n\u001b[1;32m    252\u001b[0m                                     datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), models[m].getRunId(), w))\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolling_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# incrementing the model epoch number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Cerebro Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "...\n",
    "\n",
    "backend = SparkBackend(spark_context=spark.sparkContext, num_workers=1)\n",
    "store = LocalStore(prefix_path='/Users/Lee/Documents/Research/MS_Thesis/Trial/')\n",
    "\n",
    "\n",
    "# Initialize input DataFrames.\n",
    "# You can download sample dataset from https://apache.googlesource.com/spark/+/master/data/mllib/sample_libsvm_data.txt\n",
    "df = spark.read.format(\"libsvm\").load(\"sample_libsvm_data.txt\").repartition(8)\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Define estimator generating function.\n",
    "# Input: Dictionary containing parameter values\n",
    "# Output: SparkEstimator\n",
    "def estimator_gen_fn(params):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(100, input_dim=692))\n",
    "    model.add(tf.keras.layers.Dense(1, input_dim=100))\n",
    "    model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=params['lr'])\n",
    "    loss = 'binary_crossentropy'\n",
    "\n",
    "    estimator = SparkEstimator(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['acc'],\n",
    "        batch_size=params['batch_size'])\n",
    "\n",
    "    return estimator\n",
    "\n",
    "# Define dictionary containing the parameter search space.\n",
    "search_space = {\n",
    "    'lr': hp_choice([0.001]),\n",
    "    'batch_size': hp_choice([96, 128]) #hp_quniform(96, 128, 16)\n",
    "}\n",
    "\n",
    "model_selection = TPESearch(backend=backend, store=store, estimator_gen_fn=estimator_gen_fn, search_space=search_space,\n",
    "            num_models=30, num_epochs=10, validation=0.25, evaluation_metric='loss',\n",
    "            feature_columns=['features'], label_columns=['label'])\n",
    "# model_selection = HILGridSearch(backend=backend, store=store, estimator_gen_fn=estimator_gen_fn, search_space=search_space,\n",
    "#             num_epochs=10, validation=0.25, evaluation_metric='loss',\n",
    "#             feature_columns=['features'], label_columns=['label'])\n",
    "\n",
    "# Perform model selection. Returns best model.\n",
    "model = model_selection.fit(train_df)\n",
    "\n",
    "# Inspect best model training history.\n",
    "model_history = model.get_history()\n",
    "\n",
    "# Perform inference using the best model and Spark DataFrame.\n",
    "output_df = model.set_output_columns(['label_predicted']).transform(test_df)\n",
    "output_df.select('label', 'label_predicted').show(n=10)\n",
    "\n",
    "# Access all models.\n",
    "all_models = model.get_all_models()\n",
    "all_model_training_history = model.get_all_model_history()\n",
    "\n",
    "# Convert the best model to Keras and perform inference using numpy data.\n",
    "keras_model = model.keras()\n",
    "pred = keras_model.predict([np.ones([1, 692], dtype=np.float32)])\n",
    "# Save the keras checkpoint file.\n",
    "ckpt_path = \"./ckpt_models/\"\n",
    "keras_model.save(ckpt_path)\n",
    "\n",
    "# Convert all the model to Keras.\n",
    "all_models_keras = [m.keras() for m in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import widgets_background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a46615e5d584e0ea6c1fe37ad59f824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='something 0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1251e9beb924386aae76e170790c5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='something 1')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input something!: a\n",
      "[Checkbox(value=False, description='something 0'), Checkbox(value=False, description='something 1')]\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "widgets_background.test_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45df5fc95944ba29b7d6d8a41775627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='something 0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f655819276c040afa293fba17fbce72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='something 1')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkboxes = []\n",
    "for param in range(2):\n",
    "    name = 'something ' + str(param)\n",
    "    ckb = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description=name,\n",
    "        disabled=False,\n",
    "        sync = True\n",
    "    )\n",
    "    display(ckb)\n",
    "    checkboxes.append(ckb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Ticked: something 0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(checkboxes)):\n",
    "    print(checkboxes[i].value)\n",
    "    if checkboxes[i].value:\n",
    "        print(\"Ticked: \" + checkboxes[i].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckb.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8860), started 0:05:29 ago. (Use '!kill 8860' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6896b31a38294822\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6896b31a38294822\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /Users/Lee/Documents/Research/MS_Thesis/Trial/runs/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
